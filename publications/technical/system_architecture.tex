\section{System Architecture}

The USOD architecture enforces strict separation between computationally intensive packet analysis and low-latency user interaction. The system comprises four distinct layers: Detection, Aggregation, Persistence, and Presentation.

\subsection{Detection Layer: Python Subsystem}

Network traffic analysis requires low-level access to NIC buffers, which we accomplish using \texttt{Scapy} \cite{c9} in a Python environment. This layer operates asynchronously: it captures packet headers, reconstructs flow statistics in memory, and executes pre-trained \texttt{scikit-learn} models. To avoid blocking the capture thread, inference and result processing occur in a separate \texttt{ThreadPoolExecutor}.

\begin{figure}[htbp]
\centerline{\includegraphics[width=\columnwidth]{figures/architecture-diagram}}
\caption{USOD Four-Layer Architecture. Raw packets flow from the Detection Layer to the Persistence Layer, with the Aggregation Layer serving as the orchestrator. Note the unidirectional SSE stream to clients.}
\label{fig:architecture}
\end{figure}

\subsection{Scalability Analysis}

We analyze the computational complexity of critical path components. Let $n$ denote the number of active flows and $m$ the number of blockchain peers.
\begin{itemize}
    \item \textbf{Detection}: XGBoost inference operates in $O(T \cdot d)$, where $T$ is the number of trees (100) and $d$ is the maximum depth. Since both are constants, detection is effectively $O(1)$ per packet, enabling linear scaling with $n$.
    \item \textbf{Consensus}: Raft leader election and log replication scale as $O(m)$ messages. For our configuration ($m=3$), the communication overhead is negligible.
    \item \textbf{Throughput Cap}: The theoretical transaction limit $\tau_{max}$ is governed by ordering service bandwidth $B_{bw}$ and transaction size $S_{tx}$: $\tau_{max} \approx \frac{B_{bw}}{S_{tx}}$. With $S_{tx} \approx 600$ bytes, network I/O is the limiting factor.
\end{itemize}

\subsection{Aggregation Layer: Event Orchestrator}

The aggregation layer is a Node.js middleware (Express 5.1.0) that bridges the Python detection environment and user-facing clients. This layer functions as a control plane and does not process raw traffic. It authenticates JWT signatures, enforces CORS policies, and maintains Server-Sent Events (SSE) streams. We chose SSE over WebSockets to minimize attack surface, as SSE supports only unidirectional server-to-client data flow \cite{c32}.

\subsection{Persistence Layer: Hybrid Storage Topology}

Storage responsibilities are divided according to data criticality:
\begin{itemize}
    \item \textbf{Ephemeral/User Data}: MongoDB (Mongoose v8) stores user profiles and UI preferences.
    \item \textbf{Immutable Evidence}: Threat logs are committed to Hyperledger Fabric v2.5. The ledger uses a Raft ordering service with a dedicated channel called \texttt{usod-channel}. Peers execute the \texttt{threat-logger} chaincode to validate transaction proposals before committing to the world state \cite{c23}.
\end{itemize}

\subsection{Presentation Layer}

The presentation subsystem provides synchronized operational views across three platforms:
\begin{itemize}
    \item \textbf{Web (Next.js 15)}: Uses server-side rendering (SSR) for fast initial load times and optimal search engine optimization. Communicates with the backend via REST and SSE.
    \item \textbf{Desktop (Electron 38)}: Wraps the web application in a Chromium shell \cite{c12}, enabling native OS features such as system tray icons and focus control while bypassing browser sandboxing restrictions.
    \item \textbf{Mobile (React Native 0.74)}: Compiled via Expo SDK 54, this client requires a custom adaptive polling engine (Section V-B) to circumvent iOS background WebSocket termination policies.
\end{itemize}

\begin{figure}[htbp]
\centerline{\includegraphics[width=\columnwidth]{figures/cross-platform-sync}}
\caption{Cross-Platform Synchronization Architecture. Real-time threat alerts propagate from the backend to Web (via SSE), Desktop (via SSE), and Mobile (via adaptive polling) clients.}
\label{fig:crossplatform}
\end{figure}

\subsection{Cloud Infrastructure and Containerization}

The microservices are containerized using Docker and orchestrated within an AWS Virtual Private Cloud (VPC):
\begin{itemize}
    \item \textbf{Ingress}: An Application Load Balancer (ALB) terminates SSL/TLS and routes traffic based on path prefixes (e.g., \texttt{/api/ai/} routes to the Python service).
    \item \textbf{Compute}: The backend API and AI inference services run on separate EC2 instances or ECS tasks, enabling independent scaling based on CPU load versus I/O wait patterns.
    \item \textbf{Data}: MongoDB Atlas provides a managed, auto-sharded document store. Blockchain peers run in isolated containers with persistent block storage volumes.
\end{itemize}
