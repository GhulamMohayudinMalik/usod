{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NFStream From Scratch - Real PCAP Training\n",
        "\n",
        "**Goal:** Train a model using ACTUAL NFStream-extracted features from PCAP files.\n",
        "\n",
        "## Why This Approach?\n",
        "- Previous attempts transformed CSV ‚Üí NFStream format (values still different)\n",
        "- This notebook extracts REAL features from PCAP files using NFStream\n",
        "- Model trained on actual NFStream extraction = perfect match for inference\n",
        "\n",
        "## Steps:\n",
        "1. Extract features from Monday PCAP (BENIGN) using NFStream\n",
        "2. Extract features from Friday PCAP (DDoS) using NFStream\n",
        "3. Combine and label datasets\n",
        "4. Train model on REAL NFStream features\n",
        "5. Test on held-out PCAP data\n",
        "\n",
        "## Success Criteria:\n",
        "- ‚úÖ Model detects DDoS attacks in Friday PCAP\n",
        "- ‚úÖ Accuracy > 90%\n",
        "- ‚úÖ Ready for production use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check NFStream\n",
        "try:\n",
        "    import nfstream\n",
        "    print(f\"‚úÖ NFStream version: {nfstream.__version__}\")\n",
        "except ImportError:\n",
        "    raise ImportError(\"NFStream not installed! Run: pip install nfstream\")\n",
        "\n",
        "# Set paths\n",
        "BASE_DIR = Path.cwd().parent\n",
        "PCAP_DIR = BASE_DIR / 'pcap'\n",
        "MODELS_DIR = BASE_DIR / 'models'\n",
        "RESULTS_DIR = BASE_DIR / 'results'\n",
        "DATA_DIR = BASE_DIR / 'data_processed'\n",
        "\n",
        "# Create directories\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Base directory: {BASE_DIR}\")\n",
        "print(f\"PCAP directory: {PCAP_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Extract Features from Monday PCAP (BENIGN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nfstream import NFStreamer\n",
        "\n",
        "# PCAP files\n",
        "monday_pcap = PCAP_DIR / 'Monday-WorkingHours.pcap'\n",
        "friday_pcap = PCAP_DIR / 'Friday-WorkingHours.pcap'\n",
        "\n",
        "print(\"Available PCAP files:\")\n",
        "if monday_pcap.exists():\n",
        "    print(f\"  ‚úÖ Monday: {monday_pcap.stat().st_size / (1024**3):.2f} GB (BENIGN)\")\n",
        "else:\n",
        "    print(f\"  ‚ùå Monday: Not found\")\n",
        "    \n",
        "if friday_pcap.exists():\n",
        "    print(f\"  ‚úÖ Friday: {friday_pcap.stat().st_size / (1024**3):.2f} GB (DDoS attacks)\")\n",
        "else:\n",
        "    print(f\"  ‚ùå Friday: Not found\")\n",
        "\n",
        "if not monday_pcap.exists() or not friday_pcap.exists():\n",
        "    raise FileNotFoundError(\"PCAP files not found! Check pcap/ directory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define NFStream attributes to extract\n",
        "NFSTREAM_ATTRIBUTES = [\n",
        "    'dst_port',\n",
        "    'bidirectional_duration_ms',\n",
        "    'src2dst_packets', 'dst2src_packets', 'bidirectional_packets',\n",
        "    'src2dst_bytes', 'dst2src_bytes', 'bidirectional_bytes',\n",
        "    'src2dst_max_ps', 'src2dst_min_ps', 'src2dst_mean_ps', 'src2dst_stddev_ps',\n",
        "    'dst2src_max_ps', 'dst2src_min_ps', 'dst2src_mean_ps', 'dst2src_stddev_ps',\n",
        "    'bidirectional_min_ps', 'bidirectional_max_ps', 'bidirectional_mean_ps', 'bidirectional_stddev_ps',\n",
        "    'bidirectional_mean_piat_ms', 'bidirectional_stddev_piat_ms', 'bidirectional_max_piat_ms', 'bidirectional_min_piat_ms',\n",
        "    'src2dst_duration_ms', 'src2dst_mean_piat_ms', 'src2dst_stddev_piat_ms', 'src2dst_max_piat_ms', 'src2dst_min_piat_ms',\n",
        "    'dst2src_duration_ms', 'dst2src_mean_piat_ms', 'dst2src_stddev_piat_ms', 'dst2src_max_piat_ms', 'dst2src_min_piat_ms',\n",
        "    'src2dst_psh_packets', 'src2dst_urg_packets', 'src2dst_syn_packets', 'src2dst_fin_packets', 'src2dst_rst_packets', 'src2dst_ack_packets',\n",
        "    'dst2src_psh_packets', 'dst2src_urg_packets', 'dst2src_syn_packets', 'dst2src_fin_packets', 'dst2src_rst_packets', 'dst2src_ack_packets',\n",
        "]\n",
        "\n",
        "print(f\"NFStream attributes to extract: {len(NFSTREAM_ATTRIBUTES)}\")\n",
        "\n",
        "def extract_nfstream_features(pcap_path: Path, max_flows: int = 250000, label: str = None):\n",
        "    \"\"\"Extract features from PCAP using NFStream.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Extracting from: {pcap_path.name}\")\n",
        "    print(f\"Max flows: {max_flows:,}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    streamer = NFStreamer(\n",
        "        source=str(pcap_path),\n",
        "        statistical_analysis=True,\n",
        "        splt_analysis=0,\n",
        "        n_dissections=0,\n",
        "    )\n",
        "    \n",
        "    flows_list = []\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for i, flow in enumerate(streamer):\n",
        "        # Extract only the attributes we need\n",
        "        flow_dict = {}\n",
        "        for attr in NFSTREAM_ATTRIBUTES:\n",
        "            try:\n",
        "                value = getattr(flow, attr, 0)\n",
        "                flow_dict[attr] = 0 if value is None else value\n",
        "            except:\n",
        "                flow_dict[attr] = 0\n",
        "        \n",
        "        # Add label if provided\n",
        "        if label:\n",
        "            flow_dict['Label'] = label\n",
        "        \n",
        "        flows_list.append(flow_dict)\n",
        "        \n",
        "        if (i + 1) % 25000 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
        "            print(f\"  Processed {i+1:,} flows... ({rate:.0f} flows/sec)\")\n",
        "        \n",
        "        if i + 1 >= max_flows:\n",
        "            break\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n‚úÖ Extracted {len(flows_list):,} flows in {elapsed:.2f} seconds\")\n",
        "    print(f\"   Rate: {len(flows_list)/elapsed:.0f} flows/second\")\n",
        "    \n",
        "    return pd.DataFrame(flows_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract from Monday PCAP (BENIGN)\n",
        "print(\"STEP 1: Extracting BENIGN features from Monday PCAP...\")\n",
        "df_monday = extract_nfstream_features(monday_pcap, max_flows=250000, label='BENIGN')\n",
        "\n",
        "print(f\"\\nMonday features shape: {df_monday.shape}\")\n",
        "print(f\"Columns: {len(df_monday.columns)}\")\n",
        "print(f\"Label distribution:\")\n",
        "if 'Label' in df_monday.columns:\n",
        "    print(df_monday['Label'].value_counts())\n",
        "\n",
        "# Save for inspection\n",
        "monday_csv = DATA_DIR / 'nfstream_monday_features.csv'\n",
        "df_monday.to_csv(monday_csv, index=False)\n",
        "print(f\"\\nüíæ Saved to: {monday_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Extract Features from Friday PCAP (DDoS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract from Friday PCAP (DDoS attacks)\n",
        "print(\"STEP 2: Extracting DDoS features from Friday PCAP...\")\n",
        "df_friday = extract_nfstream_features(friday_pcap, max_flows=250000, label='DDoS')\n",
        "\n",
        "print(f\"\\nFriday features shape: {df_friday.shape}\")\n",
        "print(f\"Columns: {len(df_friday.columns)}\")\n",
        "print(f\"Label distribution:\")\n",
        "if 'Label' in df_friday.columns:\n",
        "    print(df_friday['Label'].value_counts())\n",
        "\n",
        "# Save for inspection\n",
        "friday_csv = DATA_DIR / 'nfstream_friday_features.csv'\n",
        "df_friday.to_csv(friday_csv, index=False)\n",
        "print(f\"\\nüíæ Saved to: {friday_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Combine & Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine datasets\n",
        "print(\"STEP 3: Combining datasets...\")\n",
        "df_combined = pd.concat([df_monday, df_friday], ignore_index=True)\n",
        "\n",
        "print(f\"\\nCombined dataset shape: {df_combined.shape}\")\n",
        "print(f\"Label distribution:\")\n",
        "print(df_combined['Label'].value_counts())\n",
        "\n",
        "# Balance classes (take equal samples)\n",
        "benign_count = (df_combined['Label'] == 'BENIGN').sum()\n",
        "ddos_count = (df_combined['Label'] == 'DDoS').sum()\n",
        "min_count = min(benign_count, ddos_count)\n",
        "\n",
        "print(f\"\\nBalancing classes to {min_count:,} samples each...\")\n",
        "df_benign = df_combined[df_combined['Label'] == 'BENIGN'].sample(n=min_count, random_state=42)\n",
        "df_ddos = df_combined[df_combined['Label'] == 'DDoS'].sample(n=min_count, random_state=42)\n",
        "df_balanced = pd.concat([df_benign, df_ddos], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nBalanced dataset shape: {df_balanced.shape}\")\n",
        "print(f\"Label distribution:\")\n",
        "print(df_balanced['Label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and labels\n",
        "X = df_balanced.drop(columns=['Label'])\n",
        "y = df_balanced['Label']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "\n",
        "# Check for missing/infinite values\n",
        "print(f\"\\nMissing values: {X.isnull().sum().sum()}\")\n",
        "print(f\"Infinite values: {np.isinf(X.select_dtypes(include=[np.number])).sum().sum()}\")\n",
        "\n",
        "# Handle missing and infinite values\n",
        "print(\"\\nPreprocessing...\")\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "X = X.fillna(X.median())\n",
        "X = X.fillna(0)  # Fill any remaining NaN\n",
        "\n",
        "print(f\"After preprocessing:\")\n",
        "print(f\"  Missing values: {X.isnull().sum().sum()}\")\n",
        "print(f\"  Infinite values: {np.isinf(X.select_dtypes(include=[np.number])).sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"\\nTraining label distribution:\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"\\nTest label distribution:\")\n",
        "print(y_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train Random Forest Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label='DDoS', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, pos_label='DDoS', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, pos_label='DDoS', zero_division=0)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL PERFORMANCE (Test Set)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"\\nTrue Negatives (BENIGN correctly identified):  {cm[0][0]}\")\n",
        "print(f\"False Positives (BENIGN misclassified as DDoS): {cm[0][1]}\")\n",
        "print(f\"False Negatives (DDoS misclassified as BENIGN): {cm[1][0]}\")\n",
        "print(f\"True Positives (DDoS correctly identified):  {cm[1][1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Test on New PCAP Data (Held-Out) - CRITICAL TEST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract NEW flows from Friday PCAP (different portion) for testing\n",
        "print(\"STEP 7: Testing on new PCAP data (held-out)...\")\n",
        "print(\"Extracting NEW flows from Friday PCAP starting from flow 250,000...\")\n",
        "\n",
        "# Extract from a different portion of Friday PCAP\n",
        "test_streamer = NFStreamer(\n",
        "    source=str(friday_pcap),\n",
        "    statistical_analysis=True,\n",
        "    splt_analysis=0,\n",
        "    n_dissections=0,\n",
        ")\n",
        "\n",
        "test_flows = []\n",
        "skip_first = 250000  # Skip flows we already used for training\n",
        "test_count = 50000   # Test on 50K new flows\n",
        "\n",
        "print(f\"Skipping first {skip_first:,} flows, then extracting {test_count:,} flows...\")\n",
        "\n",
        "for i, flow in enumerate(test_streamer):\n",
        "    if i < skip_first:\n",
        "        continue  # Skip training flows\n",
        "    \n",
        "    flow_dict = {}\n",
        "    for attr in NFSTREAM_ATTRIBUTES:\n",
        "        try:\n",
        "            value = getattr(flow, attr, 0)\n",
        "            flow_dict[attr] = 0 if value is None else value\n",
        "        except:\n",
        "            flow_dict[attr] = 0\n",
        "    \n",
        "    test_flows.append(flow_dict)\n",
        "    \n",
        "    if (i - skip_first + 1) % 10000 == 0:\n",
        "        print(f\"  Extracted {i - skip_first + 1:,} test flows...\")\n",
        "    \n",
        "    if len(test_flows) >= test_count:\n",
        "        break\n",
        "\n",
        "df_test_pcap = pd.DataFrame(test_flows)\n",
        "print(f\"\\n‚úÖ Extracted {len(df_test_pcap):,} test flows\")\n",
        "\n",
        "# Preprocess test data\n",
        "X_test_pcap = df_test_pcap.copy()\n",
        "X_test_pcap = X_test_pcap.replace([np.inf, -np.inf], np.nan)\n",
        "X_test_pcap = X_test_pcap.fillna(X_train.median())\n",
        "X_test_pcap = X_test_pcap.fillna(0)\n",
        "\n",
        "# Ensure same column order\n",
        "X_test_pcap = X_test_pcap[X_train.columns]\n",
        "\n",
        "print(f\"Test PCAP features shape: {X_test_pcap.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test PCAP data\n",
        "print(\"Making predictions on test PCAP data...\")\n",
        "test_predictions = rf_model.predict(X_test_pcap)\n",
        "\n",
        "# Analyze results\n",
        "pred_counts = pd.Series(test_predictions).value_counts()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST PCAP ANALYSIS RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total flows analyzed: {len(test_predictions):,}\")\n",
        "print(f\"\\nPrediction Distribution:\")\n",
        "for label, count in pred_counts.items():\n",
        "    pct = count / len(test_predictions) * 100\n",
        "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
        "\n",
        "# This is Friday PCAP, so we expect DDoS attacks\n",
        "ddos_detected = (test_predictions == 'DDoS').sum()\n",
        "benign_detected = (test_predictions == 'BENIGN').sum()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"VERDICT:\")\n",
        "print(f\"{'='*60}\")\n",
        "if ddos_detected > benign_detected:\n",
        "    print(\"‚úÖ SUCCESS! Model correctly detects DDoS attacks in Friday PCAP!\")\n",
        "    print(f\"   DDoS detected: {ddos_detected:,} ({ddos_detected/len(test_predictions)*100:.1f}%)\")\n",
        "    print(f\"   BENIGN detected: {benign_detected:,} ({benign_detected/len(test_predictions)*100:.1f}%)\")\n",
        "    print(\"\\nüéâ NFStream model works! Ready for production.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: Model did not detect DDoS attacks correctly\")\n",
        "    print(f\"   DDoS detected: {ddos_detected:,} ({ddos_detected/len(test_predictions)*100:.1f}%)\")\n",
        "    print(f\"   BENIGN detected: {benign_detected:,} ({benign_detected/len(test_predictions)*100:.1f}%)\")\n",
        "    print(\"\\n‚ö†Ô∏è Consider using CICFlowMeter instead.\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Save Model (If Successful)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model if it works\n",
        "import joblib\n",
        "\n",
        "# Check if model detected attacks correctly\n",
        "if ddos_detected > benign_detected:\n",
        "    print(\"Saving model...\")\n",
        "    \n",
        "    model_filename = MODELS_DIR / 'random_forest_nfstream_from_scratch.joblib'\n",
        "    joblib.dump(rf_model, model_filename)\n",
        "    print(f\"‚úÖ Model saved: {model_filename}\")\n",
        "    \n",
        "    # Save feature names\n",
        "    feature_names_file = MODELS_DIR / 'feature_names_nfstream_from_scratch.joblib'\n",
        "    joblib.dump(list(X_train.columns), feature_names_file)\n",
        "    print(f\"‚úÖ Feature names saved: {feature_names_file}\")\n",
        "    \n",
        "    # Save class names\n",
        "    class_names_file = MODELS_DIR / 'class_names_nfstream_from_scratch.joblib'\n",
        "    joblib.dump(['BENIGN', 'DDoS'], class_names_file)\n",
        "    print(f\"‚úÖ Class names saved: {class_names_file}\")\n",
        "    \n",
        "    print(\"\\nüéâ Model saved successfully!\")\n",
        "    print(\"\\nYou can now use this model for PCAP analysis with NFStream.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Model not saved - did not pass validation test\")\n",
        "    print(\"   Consider using CICFlowMeter instead.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
