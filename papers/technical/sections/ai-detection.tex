The AI-Enhanced Detection system represents a significant advancement in USOD's threat detection capabilities, leveraging machine learning algorithms to identify attack patterns and provide intelligent security analysis. The AI integration extends the traditional pattern-based detection with ML-based network traffic analysis.

\subsection{AI Service Architecture}

The AI integration follows a modular microservices architecture with a dedicated Python FastAPI service communicating with the Node.js backend via REST APIs and webhooks.

\textbf{Python FastAPI Service}: The AI service runs on port 8000, built with FastAPI for high-performance async request handling. The service provides endpoints for health checks, threat detection, PCAP analysis, model statistics, and real-time monitoring control.

\textbf{Machine Learning Pipeline}: The pipeline includes data preprocessing using pandas, feature extraction from network flows, model training with scikit-learn, and real-time inference. Models are pre-trained using the CICIDS2017 dataset and loaded at service startup for immediate inference.

\textbf{Backend Integration}: The AI service communicates with the Node.js backend through HTTP webhooks for automatic threat forwarding. Detected threats are logged to MongoDB and optionally to the Hyperledger Fabric blockchain for immutable audit trails.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\columnwidth]{figures/ai-architecture.png}
\caption{AI-Enhanced Detection Architecture}
\label{fig:ai-architecture}
\end{figure}

\subsection{Dataset and Training}

The ML models are trained on the CICIDS2017 dataset, a comprehensive benchmark for network intrusion detection.

\textbf{CICIDS2017 Dataset}: The training data comprises 8 CSV files totaling approximately 843MB, containing labeled network traffic with 5 attack classes: Bot, DoS slowloris, FTP-Patator, PortScan, and Benign traffic.

\textbf{Feature Engineering}: 25 key features are extracted from the original 78 CICIDS features, optimizing inference time while maintaining detection accuracy. Features include flow duration, packet counts, byte counts, inter-arrival times, and flag statistics.

\textbf{Training Pipeline}: The fast training pipeline (model\_training\_fast.py) completes in approximately 5 minutes on standard hardware, enabling rapid model iteration during development.

\subsection{Machine Learning Models}

USOD implements two complementary machine learning models optimized for different aspects of threat detection.

\textbf{Random Forest Classifier}: The primary classification model uses 100-200 decision tree estimators trained on CICIDS2017 labeled data. The model achieves 99.97\% accuracy on the test split with precision of 1.0, recall of 0.9909, and F1-score of 0.9954. Model file size is 909KB, and average inference time is 34.51ms per flow.

\textbf{Isolation Forest Anomaly Detector}: The unsupervised anomaly detection model uses 100-200 estimators with 0.1-0.2 contamination rate, achieving 87.33\% accuracy on CICIDS2017 data. This model enables detection of previously unseen attack patterns that may not match supervised classification boundaries.

\subsubsection{Model Implementation}

\begin{lstlisting}[language=Python, caption=AI Detection Service Implementation, basicstyle=\footnotesize\ttfamily, breaklines=true]
from fastapi import FastAPI
from sklearn.ensemble import RandomForestClassifier, IsolationForest
import joblib
import numpy as np

app = FastAPI(title="USOD Network AI Service")

# Load pre-trained models at startup
rf_model = joblib.load('usod_models/random_forest_model.pkl')
if_model = joblib.load('usod_models/isolation_forest_model.pkl')

class ThreatDetector:
    def __init__(self):
        self.rf_model = rf_model
        self.if_model = if_model
        self.feature_names = [
            'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',
            'Flow Bytes/s', 'Flow Packets/s', 'Fwd Packet Length Mean',
            'Bwd Packet Length Mean', 'Flow IAT Mean', 'Flow IAT Std',
            # ... 25 selected features
        ]
    
    def detect_threat(self, flow_features):
        """Classify network flow using Random Forest"""
        features = np.array(flow_features).reshape(1, -1)
        prediction = self.rf_model.predict(features)[0]
        probability = self.rf_model.predict_proba(features)[0]
        confidence = float(np.max(probability))
        
        return {
            'threat_type': prediction,
            'confidence': confidence,
            'is_threat': prediction != 'BENIGN'
        }
    
    def detect_anomaly(self, flow_features):
        """Detect anomalies using Isolation Forest"""
        features = np.array(flow_features).reshape(1, -1)
        anomaly_score = self.if_model.decision_function(features)[0]
        is_anomaly = self.if_model.predict(features)[0] == -1
        
        return {
            'is_anomaly': bool(is_anomaly),
            'anomaly_score': float(anomaly_score)
        }

@app.post("/api/detect")
async def detect_threat(flow_data: dict):
    detector = ThreatDetector()
    rf_result = detector.detect_threat(flow_data['features'])
    if_result = detector.detect_anomaly(flow_data['features'])
    
    return {
        'classification': rf_result,
        'anomaly_detection': if_result,
        'timestamp': datetime.now().isoformat()
    }
\end{lstlisting}

\subsection{Network Traffic Analysis}

The network traffic analysis component processes network flows for threat detection.

\textbf{Flow Extraction}: The system extracts network flow features from packet captures, computing statistics including packet counts, byte volumes, inter-arrival times, and TCP flag distributions.

\textbf{SimpleDetector Mode}: For development and demonstration, the SimpleDetector class generates mock network flows enabling system testing without administrator privileges for packet capture.

\textbf{Scapy Integration}: Full packet capture capabilities using Scapy are available for production deployment with administrator privileges, enabling real-time network monitoring.

\subsection{Real-time Threat Detection}

The system provides real-time threat detection with immediate notification across all platforms.

\textbf{Webhook Integration}: Detected threats are automatically forwarded from the Python AI service to the Node.js backend via HTTP POST webhooks, enabling immediate logging and notification.

\textbf{SSE Streaming}: Server-Sent Events (SSE) stream detected threats from the backend to all connected frontend clients with sub-100ms latency.

\textbf{EventBus Broadcasting}: The Node.js EventEmitter-based system broadcasts threat events to all connected clients, supporting 5 specific event types for network monitoring.

\subsection{PCAP Analysis}

The system supports offline analysis of packet capture files.

\textbf{File Upload}: PCAP files can be uploaded through the /api/network/upload-pcap endpoint for batch analysis.

\textbf{Flow Extraction}: The service extracts network flows from PCAP files and applies the trained ML models for threat classification.

\textbf{Results Reporting}: Analysis results include threat classifications, confidence scores, and detailed flow statistics.

\subsection{API Endpoints}

The AI service exposes a comprehensive REST API for threat detection operations.

\textbf{Monitoring Control}: POST /api/network/start-monitoring initiates real-time network monitoring; POST /api/network/stop-monitoring terminates monitoring.

\textbf{Threat Retrieval}: GET /api/network/threats retrieves detected network threats; GET /api/network/statistics provides model performance statistics.

\textbf{Service Status}: GET /api/network/status returns monitoring status and health; GET /api/network/health provides service health check.

\textbf{PCAP Analysis}: POST /api/network/upload-pcap accepts PCAP file uploads for offline analysis.

\textbf{Real-time Stream}: GET /api/network/stream provides SSE endpoint for live threat streaming with JWT authentication.

\subsection{Database Integration}

Detected threats are automatically stored with comprehensive metadata.

\textbf{MongoDB Storage}: The SecurityLog model includes 9 network threat action types, storing complete threat details including confidence scores, severity levels, and timestamps.

\textbf{Blockchain Logging}: Critical threats are optionally logged to the Hyperledger Fabric blockchain for immutable audit trails.

\textbf{Automatic Logging}: Every detected threat is automatically stored without manual intervention, creating comprehensive security audit trails.

\subsection{Performance Evaluation}

The AI detection system demonstrates production-ready performance characteristics.

\textbf{Detection Accuracy}: Random Forest achieves 99.97\% accuracy on CICIDS2017 test data. These metrics are validated on the specific test split and may vary on different datasets.

\textbf{Inference Performance}: Average processing time of 34.51ms per network flow enables real-time threat detection. The Python FastAPI service adds approximately 10-50ms latency for ML prediction per request.

\textbf{End-to-End Latency}: Complete threat detection pipeline from Python service to Node.js backend via webhook completes in under 100ms.

\textbf{Resource Utilization}: The FastAPI service maintains base memory usage of approximately 100MB plus model overhead. Models are loaded once at startup and cached in memory.

\subsection{Model Limitations}

The evaluation identifies important limitations for production consideration.

\textbf{Dataset Scope}: Models are trained on CICIDS2017 data from 2017. Detection accuracy on modern attack patterns not represented in the training data may vary. Continuous model retraining with current threat data is recommended for production deployment.

\textbf{Network Dependency}: Real-time monitoring requires network packet capture capabilities, which may require administrator privileges on production systems.

\textbf{Feature Extraction}: The current feature extraction assumes compatible network flow formats. PCAP files with non-standard formats may require preprocessing.

\subsection{Research Assets}

The implementation includes preserved research assets for academic documentation.

\textbf{Visualization Plots}: All training visualization plots are preserved in the project for technical paper figures.

\textbf{Model Artifacts}: Trained model files (random\_forest\_model.pkl, isolation\_forest\_model.pkl) and training logs are preserved for reproducibility.

\textbf{Performance Metrics}: Detailed accuracy metrics, confusion matrices, and ROC curves are documented for evaluation.

